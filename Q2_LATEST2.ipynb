{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac03b351-244a-49ae-bf72-437973d84fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# regression analysis\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb30168",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb93bc5c-55a7-4ff2-ac34-3357ea22fbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>RACED</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>EDUCD</th>\n",
       "      <th>DEGFIELD</th>\n",
       "      <th>DEGFIELDD</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>EMPSTATD</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>PWSTATE2</th>\n",
       "      <th>TRANTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>801</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>12500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>16400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373373</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>1199</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373374</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>23</td>\n",
       "      <td>2305</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373375</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999999</td>\n",
       "      <td>99999</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373376</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>162000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373377</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3373378 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGION  SEX  AGE  MARST  RACE  RACED  HCOVANY  EDUC  EDUCD  DEGFIELD  \\\n",
       "0            32    2   85      5     8    801        2     7     71         0   \n",
       "1            32    1   51      5     1    100        2     6     64         0   \n",
       "2            32    2   36      6     2    200        2     2     26         0   \n",
       "3            32    1   74      6     2    200        2     0      2         0   \n",
       "4            32    1   49      4     1    100        1     7     71         0   \n",
       "...         ...  ...  ...    ...   ...    ...      ...   ...    ...       ...   \n",
       "3373373      41    1   33      6     1    100        2    10    101        11   \n",
       "3373374      41    2   27      6     1    100        2    10    101        23   \n",
       "3373375      41    1    1      6     1    100        2     0      1         0   \n",
       "3373376      41    1   66      1     1    100        2     6     63         0   \n",
       "3373377      41    2   58      1     1    100        2     6     64         0   \n",
       "\n",
       "         DEGFIELDD  EMPSTAT  EMPSTATD  INCWAGE  INCWELFR  INCINVST  PWSTATE2  \\\n",
       "0                0        3        30        0         0         0         0   \n",
       "1                0        3        30    12500         0         0         0   \n",
       "2                0        3        30    16400         0         0         0   \n",
       "3                0        3        30        0         0         0         0   \n",
       "4                0        3        30        0         0         0         0   \n",
       "...            ...      ...       ...      ...       ...       ...       ...   \n",
       "3373373       1199        1        10    52000         0         0        56   \n",
       "3373374       2305        1        10    43000         0         0        56   \n",
       "3373375          0        0         0   999999     99999    999999         0   \n",
       "3373376          0        1        10   162000         0         0        56   \n",
       "3373377          0        1        10    25000         0         0        56   \n",
       "\n",
       "         TRANTIME  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "3373373        10  \n",
       "3373374        45  \n",
       "3373375         0  \n",
       "3373376        10  \n",
       "3373377         3  \n",
       "\n",
       "[3373378 rows x 18 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage_data = pd.read_csv('data/usa_00006.csv.gz', compression=\"gzip\")\n",
    "wage_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d839b77e-f9c9-46d8-aa4f-08e47d6569d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>DEGFIELD</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>TRANTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373373</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373374</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373375</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999999</td>\n",
       "      <td>99999</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373376</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373377</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3373378 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGION  SEX  AGE  MARST  RACE  HCOVANY  EDUC  DEGFIELD  EMPSTAT  \\\n",
       "0            32    2   85      5     8        2     7         0        3   \n",
       "1            32    1   51      5     1        2     6         0        3   \n",
       "2            32    2   36      6     2        2     2         0        3   \n",
       "3            32    1   74      6     2        2     0         0        3   \n",
       "4            32    1   49      4     1        1     7         0        3   \n",
       "...         ...  ...  ...    ...   ...      ...   ...       ...      ...   \n",
       "3373373      41    1   33      6     1        2    10        11        1   \n",
       "3373374      41    2   27      6     1        2    10        23        1   \n",
       "3373375      41    1    1      6     1        2     0         0        0   \n",
       "3373376      41    1   66      1     1        2     6         0        1   \n",
       "3373377      41    2   58      1     1        2     6         0        1   \n",
       "\n",
       "         INCWAGE  INCWELFR  INCINVST  TRANTIME  \n",
       "0              0         0         0         0  \n",
       "1          12500         0         0         0  \n",
       "2          16400         0         0         0  \n",
       "3              0         0         0         0  \n",
       "4              0         0         0         0  \n",
       "...          ...       ...       ...       ...  \n",
       "3373373    52000         0         0        10  \n",
       "3373374    43000         0         0        45  \n",
       "3373375   999999     99999    999999         0  \n",
       "3373376   162000         0         0        10  \n",
       "3373377    25000         0         0         3  \n",
       "\n",
       "[3373378 rows x 13 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage_data = wage_data.drop(columns=['RACED', 'EDUCD','DEGFIELDD', 'EMPSTATD', 'PWSTATE2'])\n",
    "wage_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881323a",
   "metadata": {},
   "source": [
    "#### Data Code\n",
    "\n",
    "##### Race Codes: \n",
    "\n",
    "1\tWhite\t\n",
    "2\tBlack/African American\t\n",
    "3\tAmerican Indian or Alaska Native\t\n",
    "4\tChinese\t\n",
    "5\tJapanese\t\n",
    "6\tOther Asian or Pacific Islander\t\n",
    "7\tOther race, nec\t\n",
    "8\tTwo major races\t\n",
    "9\tThree or more major races\n",
    "\n",
    "##### HCOVANY Codes: \n",
    "\n",
    "1\tNo health insurance coverage\t\n",
    "2\tWith health insurance coverage\n",
    "\n",
    "##### EDUC codes:\n",
    "\n",
    "00\tN/A or no schooling\tX\n",
    "01\tNursery school to grade 4\tX\n",
    "02\tGrade 5, 6, 7, or 8\tX\n",
    "03\tGrade 9\tX\n",
    "04\tGrade 10\tX\n",
    "05\tGrade 11\tX\n",
    "06\tGrade 12\tX\n",
    "07\t1 year of college\tX\n",
    "08\t2 years of college\tX\n",
    "09\t3 years of college\t·\n",
    "10\t4 years of college\tX\n",
    "11\t5+ years of college\tX\n",
    "99\tMissing\n",
    "\n",
    "\n",
    "##### DEGFIELD Codes: \n",
    "\n",
    "00\tN/A\tX\n",
    "11\tAgriculture\tX\n",
    "13\tEnvironment and Natural Resources\tX\n",
    "14\tArchitecture\tX\n",
    "15\tArea, Ethnic, and Civilization Studies\tX\n",
    "19\tCommunications\tX\n",
    "20\tCommunication Technologies\tX\n",
    "21\tComputer and Information Sciences\tX\n",
    "22\tCosmetology Services and Culinary Arts\tX\n",
    "23\tEducation Administration and Teaching\tX\n",
    "24\tEngineering\tX\n",
    "25\tEngineering Technologies\tX\n",
    "26\tLinguistics and Foreign Languages\tX\n",
    "29\tFamily and Consumer Sciences\tX\n",
    "32\tLaw\tX\n",
    "33\tEnglish Language, Literature, and Composition\tX\n",
    "34\tLiberal Arts and Humanities\tX\n",
    "35\tLibrary Science\tX\n",
    "36\tBiology and Life Sciences\tX\n",
    "37\tMathematics and Statistics\tX\n",
    "38\tMilitary Technologies\tX\n",
    "40\tInterdisciplinary and Multi-Disciplinary Studies (General)\tX\n",
    "41\tPhysical Fitness, Parks, Recreation, and Leisure\tX\n",
    "48\tPhilosophy and Religious Studies\tX\n",
    "49\tTheology and Religious Vocations\tX\n",
    "50\tPhysical Sciences\tX\n",
    "51\tNuclear, Industrial Radiology, and Biological Technologies\tX\n",
    "52\tPsychology\tX\n",
    "53\tCriminal Justice and Fire Protection\tX\n",
    "54\tPublic Affairs, Policy, and Social Work\tX\n",
    "55\tSocial Sciences\tX\n",
    "56\tConstruction Services\tX\n",
    "57\tElectrical and Mechanic Repairs and Technologies\tX\n",
    "58\tPrecision Production and Industrial Arts\t·\n",
    "59\tTransportation Sciences and Technologies\tX\n",
    "60\tFine Arts\tX\n",
    "61\tMedical and Health Sciences and Services\tX\n",
    "62\tBusiness\tX\n",
    "64\tHistory\n",
    "\n",
    "\n",
    "##### PWSTATE2:\n",
    "\n",
    "00\tN/A\tX\n",
    "01\tAlabama\tX\n",
    "02\tAlaska\tX\n",
    "04\tArizona\tX\n",
    "05\tArkansas\tX\n",
    "06\tCalifornia\tX\n",
    "08\tColorado\tX\n",
    "09\tConnecticut\tX\n",
    "10\tDelaware\tX\n",
    "11\tDistrict of Columbia\tX\n",
    "12\tFlorida\tX\n",
    "13\tGeorgia\tX\n",
    "15\tHawaii\tX\n",
    "16\tIdaho\tX\n",
    "17\tIllinois\tX\n",
    "18\tIndiana\tX\n",
    "19\tIowa\tX\n",
    "20\tKansas\tX\n",
    "21\tKentucky\tX\n",
    "22\tLouisiana\tX\n",
    "23\tMaine\tX\n",
    "24\tMaryland\tX\n",
    "25\tMassachusetts\tX\n",
    "26\tMichigan\tX\n",
    "27\tMinnesota\tX\n",
    "28\tMississippi\tX\n",
    "29\tMissouri\tX\n",
    "30\tMontana\tX\n",
    "31\tNebraska\tX\n",
    "32\tNevada\tX\n",
    "33\tNew Hampshire\tX\n",
    "34\tNew Jersey\tX\n",
    "35\tNew Mexico\tX\n",
    "36\tNew York\tX\n",
    "37\tNorth Carolina\tX\n",
    "38\tNorth Dakota\tX\n",
    "39\tOhio\tX\n",
    "40\tOklahoma\tX\n",
    "41\tOregon\tX\n",
    "42\tPennsylvania\tX\n",
    "44\tRhode Island\tX\n",
    "45\tSouth Carolina\tX\n",
    "46\tSouth Dakota\tX\n",
    "47\tTennessee\tX\n",
    "48\tTexas\tX\n",
    "49\tUtah\tX\n",
    "50\tVermont\tX\n",
    "51\tVirginia\tX\n",
    "53\tWashington\tX\n",
    "54\tWest Virginia\tX\n",
    "55\tWisconsin\tX\n",
    "56\tWyoming\tX\n",
    "\n",
    "##### State group codes (UR samples)\t\n",
    "61\tMaine-New Hampshire-Vermont\t·\n",
    "62\tMassachusetts-Rhode Island\t·\n",
    "63\tMinnesota-Iowa-Missouri-Kansas-Nebraska-S.Dakota-N.Dakota\t·\n",
    "64\tMaryland-Delaware\t·\n",
    "65\tMontana-Idaho-Wyoming\t·\n",
    "66\tUtah-Nevada\t·\n",
    "67\tArizona-New Mexico\t·\n",
    "68\tAlaska-Hawaii\t·\n",
    "72\tPuerto Rico\tX\n",
    "73\tU.S. outlying area\t·\n",
    "74\tUnited States (1980 Puerto Rico samples)\t·\n",
    "80\tAbroad\t·\n",
    "81\tEurope\tX\n",
    "82\tEastern Asia\t·\n",
    "83\tOther Asia, n.s. (2003-2005 ACS); South Central, South East, and Western Asia (2000-2002 ACS)\tX\n",
    "84\tMexico\tX\n",
    "85\tOther Americas\tX\n",
    "86\tOther, n.e.c.\tX\n",
    "87\tIraq\t·\n",
    "88\tCanada\t·\n",
    "90\tConfidential\t·\n",
    "99\tNot reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17d392f7-72df-4ef0-8676-6cfd960532ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>DEGFIELD</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>TRANTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373372</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373373</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373374</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373376</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373377</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2809390 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGION  SEX  AGE  MARST  RACE  HCOVANY  EDUC  DEGFIELD  EMPSTAT  \\\n",
       "0            32    2   85      5     8        2     7         0        3   \n",
       "1            32    1   51      5     1        2     6         0        3   \n",
       "2            32    2   36      6     2        2     2         0        3   \n",
       "3            32    1   74      6     2        2     0         0        3   \n",
       "4            32    1   49      4     1        1     7         0        3   \n",
       "...         ...  ...  ...    ...   ...      ...   ...       ...      ...   \n",
       "3373372      41    1   55      6     1        2     6         0        1   \n",
       "3373373      41    1   33      6     1        2    10        11        1   \n",
       "3373374      41    2   27      6     1        2    10        23        1   \n",
       "3373376      41    1   66      1     1        2     6         0        1   \n",
       "3373377      41    2   58      1     1        2     6         0        1   \n",
       "\n",
       "         INCWAGE  INCWELFR  INCINVST  TRANTIME  \n",
       "0              0         0         0         0  \n",
       "1          12500         0         0         0  \n",
       "2          16400         0         0         0  \n",
       "3              0         0         0         0  \n",
       "4              0         0         0         0  \n",
       "...          ...       ...       ...       ...  \n",
       "3373372    21800         0         0        13  \n",
       "3373373    52000         0         0        10  \n",
       "3373374    43000         0         0        45  \n",
       "3373376   162000         0         0        10  \n",
       "3373377    25000         0         0         3  \n",
       "\n",
       "[2809390 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where INCWAGE is 999999 (N/A)\n",
    "# revome rows where income is na\n",
    "wage_data.dropna(subset=['INCWAGE'], inplace=True)\n",
    "wage_data = wage_data[wage_data['INCWAGE'] != 999999]\n",
    "wage_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69f36505-5974-47ea-bcce-891280470b32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>DEGFIELD</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>TRANTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "      <td>2.809390e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.839617e+01</td>\n",
       "      <td>1.513144e+00</td>\n",
       "      <td>4.975876e+01</td>\n",
       "      <td>3.123662e+00</td>\n",
       "      <td>2.414484e+00</td>\n",
       "      <td>1.921980e+00</td>\n",
       "      <td>7.418151e+00</td>\n",
       "      <td>1.414194e+01</td>\n",
       "      <td>1.855315e+00</td>\n",
       "      <td>3.521161e+04</td>\n",
       "      <td>4.859950e+01</td>\n",
       "      <td>3.015792e+03</td>\n",
       "      <td>1.224302e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.027669e+01</td>\n",
       "      <td>4.998273e-01</td>\n",
       "      <td>1.974501e+01</td>\n",
       "      <td>2.240868e+00</td>\n",
       "      <td>2.509463e+00</td>\n",
       "      <td>2.682033e-01</td>\n",
       "      <td>2.467408e+00</td>\n",
       "      <td>2.257371e+01</td>\n",
       "      <td>9.777120e-01</td>\n",
       "      <td>6.538914e+04</td>\n",
       "      <td>6.935578e+02</td>\n",
       "      <td>2.496205e+04</td>\n",
       "      <td>2.030420e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>7.910000e+05</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>4.680000e+05</td>\n",
       "      <td>1.580000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             REGION           SEX           AGE         MARST          RACE  \\\n",
       "count  2.809390e+06  2.809390e+06  2.809390e+06  2.809390e+06  2.809390e+06   \n",
       "mean   2.839617e+01  1.513144e+00  4.975876e+01  3.123662e+00  2.414484e+00   \n",
       "std    1.027669e+01  4.998273e-01  1.974501e+01  2.240868e+00  2.509463e+00   \n",
       "min    1.100000e+01  1.000000e+00  1.600000e+01  1.000000e+00  1.000000e+00   \n",
       "25%    2.100000e+01  1.000000e+00  3.300000e+01  1.000000e+00  1.000000e+00   \n",
       "50%    3.100000e+01  2.000000e+00  5.000000e+01  2.000000e+00  1.000000e+00   \n",
       "75%    3.300000e+01  2.000000e+00  6.600000e+01  6.000000e+00  2.000000e+00   \n",
       "max    4.200000e+01  2.000000e+00  9.700000e+01  6.000000e+00  9.000000e+00   \n",
       "\n",
       "            HCOVANY          EDUC      DEGFIELD       EMPSTAT       INCWAGE  \\\n",
       "count  2.809390e+06  2.809390e+06  2.809390e+06  2.809390e+06  2.809390e+06   \n",
       "mean   1.921980e+00  7.418151e+00  1.414194e+01  1.855315e+00  3.521161e+04   \n",
       "std    2.682033e-01  2.467408e+00  2.257371e+01  9.777120e-01  6.538914e+04   \n",
       "min    1.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "25%    2.000000e+00  6.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "50%    2.000000e+00  7.000000e+00  0.000000e+00  1.000000e+00  9.000000e+03   \n",
       "75%    2.000000e+00  1.000000e+01  2.400000e+01  3.000000e+00  5.000000e+04   \n",
       "max    2.000000e+00  1.100000e+01  6.400000e+01  3.000000e+00  7.910000e+05   \n",
       "\n",
       "           INCWELFR      INCINVST      TRANTIME  \n",
       "count  2.809390e+06  2.809390e+06  2.809390e+06  \n",
       "mean   4.859950e+01  3.015792e+03  1.224302e+01  \n",
       "std    6.935578e+02  2.496205e+04  2.030420e+01  \n",
       "min    0.000000e+00 -3.000000e+03  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "75%    0.000000e+00  0.000000e+00  2.000000e+01  \n",
       "max    3.000000e+04  4.680000e+05  1.580000e+02  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a5063",
   "metadata": {},
   "source": [
    "#### Winsorize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c832a5e6-f161-4ee8-a31c-61011f692a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def winsorize_series(series, lower_percentile=0.01, upper_percentile=0.99):\n",
    "    lower_limit = series.quantile(lower_percentile)\n",
    "    upper_limit = series.quantile(upper_percentile)\n",
    "    return series.clip(lower=lower_limit, upper=upper_limit)\n",
    "\n",
    "# Assuming your data is in a DataFrame named wage_data\n",
    "# Explicitly use .loc to avoid SettingWithCopyWarning\n",
    "wage_data = wage_data.copy()  # Ensure it's a standalone DataFrame\n",
    "wage_data.loc[:, 'INCWAGE'] = winsorize_series(wage_data['INCWAGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a95d6",
   "metadata": {},
   "source": [
    "The below graph describes the wage = 0 distribution against age to decide if we will drop 0 wages. \n",
    "\n",
    "The result of the below graph indicates that there are more occurrences of 0 wages when the subject is less than 20 years old(in school) or when the subject is above 55 years old(retired maybe?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "480b0028-ed5f-4d49-842e-57bce79b9077",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wage_zero_data = wage_data[wage_data['INCWAGE'] == 0].groupby('AGE')['INCWAGE'].count()\n",
    "\n",
    "mean_wage_by_age = wage_data[wage_data['INCWAGE'] > 0].groupby('AGE')['INCWAGE'].mean()\n",
    "\n",
    "\n",
    "plt.bar(wage_zero_data.index, wage_zero_data.values, color='lightcoral', alpha=0.7, label='Frequency of Zero Wages')\n",
    "\n",
    "plt.plot(mean_wage_by_age.index, mean_wage_by_age.values, color='blue', marker='o', label='Mean Wage (Excluding Zero Wages)')\n",
    "\n",
    "plt.title('Wage Distribution by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Wage / Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f57214",
   "metadata": {},
   "source": [
    "### Education data Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaa6d2b9-5ab6-4ccd-98e4-9f5226de631a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>DEGFIELD</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>TRANTIME</th>\n",
       "      <th>No_to_Grade_8</th>\n",
       "      <th>Grade_9_to_12</th>\n",
       "      <th>One_to_Two_College</th>\n",
       "      <th>Three_to_Four_College</th>\n",
       "      <th>Five_or_More_Years_College</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373372</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373373</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373374</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373376</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373377</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2809390 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGION  SEX  AGE  MARST  RACE  HCOVANY  DEGFIELD  EMPSTAT  INCWAGE  \\\n",
       "0            32    2   85      5     8        2         0        3        0   \n",
       "1            32    1   51      5     1        2         0        3    12500   \n",
       "2            32    2   36      6     2        2         0        3    16400   \n",
       "3            32    1   74      6     2        2         0        3        0   \n",
       "4            32    1   49      4     1        1         0        3        0   \n",
       "...         ...  ...  ...    ...   ...      ...       ...      ...      ...   \n",
       "3373372      41    1   55      6     1        2         0        1    21800   \n",
       "3373373      41    1   33      6     1        2        11        1    52000   \n",
       "3373374      41    2   27      6     1        2        23        1    43000   \n",
       "3373376      41    1   66      1     1        2         0        1   162000   \n",
       "3373377      41    2   58      1     1        2         0        1    25000   \n",
       "\n",
       "         INCWELFR  INCINVST  TRANTIME  No_to_Grade_8  Grade_9_to_12  \\\n",
       "0               0         0         0              0              0   \n",
       "1               0         0         0              0              1   \n",
       "2               0         0         0              1              0   \n",
       "3               0         0         0              1              0   \n",
       "4               0         0         0              0              0   \n",
       "...           ...       ...       ...            ...            ...   \n",
       "3373372         0         0        13              0              1   \n",
       "3373373         0         0        10              0              0   \n",
       "3373374         0         0        45              0              0   \n",
       "3373376         0         0        10              0              1   \n",
       "3373377         0         0         3              0              1   \n",
       "\n",
       "         One_to_Two_College  Three_to_Four_College  Five_or_More_Years_College  \n",
       "0                         1                      0                           0  \n",
       "1                         0                      0                           0  \n",
       "2                         0                      0                           0  \n",
       "3                         0                      0                           0  \n",
       "4                         1                      0                           0  \n",
       "...                     ...                    ...                         ...  \n",
       "3373372                   0                      0                           0  \n",
       "3373373                   0                      1                           0  \n",
       "3373374                   0                      1                           0  \n",
       "3373376                   0                      0                           0  \n",
       "3373377                   0                      0                           0  \n",
       "\n",
       "[2809390 rows x 17 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Educational attainment mapping\n",
    "educ_mapping = {\n",
    "    0: 'No_to_Grade_8',  # Includes codes 0, 1, 2, 99\n",
    "    1: 'Grade_9_to_12',  # Includes codes 3, 4, 5, 6\n",
    "    2: 'One_to_Two_College',  # Includes codes 7, 8\n",
    "    3: 'Three_to_Four_College',  # Includes codes 9, 10\n",
    "    4: 'Five_or_More_Years_College'  # Includes codes 11\n",
    "}\n",
    "\n",
    "educ_group_codes = {\n",
    "    'No_to_Grade_8': [0, 1, 2, 99],\n",
    "    'Grade_9_to_12': [3, 4, 5, 6],\n",
    "    'One_to_Two_College': [7, 8],\n",
    "    'Three_to_Four_College': [9, 10],\n",
    "    'Five_or_More_Years_College': [11]\n",
    "}\n",
    "\n",
    "for group_name, codes in educ_group_codes.items():\n",
    "    wage_data[group_name] = wage_data['EDUC'].isin(codes).astype(int)\n",
    "\n",
    "wage_data = wage_data.drop(columns=['EDUC'])\n",
    "wage_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ae461-852b-409a-a65c-7834325d2a23",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b74177d9",
   "metadata": {},
   "source": [
    "### Degree Field Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7043b0e-f0af-4139-bf7b-617705973af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "degfield_mapping = {\n",
    "    0: 'General_and_Undefined',  # Includes codes 0, 40\n",
    "    1: 'STEM',  # Includes codes 11, 13, 14, 21, 24, 25, 36, 37, 50, 51, 52\n",
    "    2: 'Humanities_Arts_and_Social_Sciences',  # Includes codes 15, 26, 29, 33, 34, 48, 49, 54, 55, 60, 64\n",
    "    3: 'Business_Law_and_Communication',  # Includes codes 19, 20, 32, 62\n",
    "    4: 'Vocational_Health_and_Education'  # Includes codes 22, 23, 35, 41, 56, 57, 59, 61, 38, 53\n",
    "}\n",
    "\n",
    "degfield_group_codes = {\n",
    "    'General_and_Undefined': [0, 40],\n",
    "    'STEM': [11, 13, 14, 21, 24, 25, 36, 37, 50, 51, 52],\n",
    "    'Humanities_Arts_and_Social_Sciences': [15, 26, 29, 33, 34, 48, 49, 54, 55, 60, 64],\n",
    "    'Business_Law_and_Communication': [19, 20, 32, 62],\n",
    "    'Vocational_Health_and_Education': [22, 23, 35, 41, 56, 57, 59, 61, 38, 53]\n",
    "}\n",
    "\n",
    "for group_name, codes in degfield_group_codes.items():\n",
    "    wage_data[group_name] = wage_data['DEGFIELD'].isin(codes).astype(int)\n",
    "\n",
    "wage_data = wage_data.drop(columns=['DEGFIELD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66f2d85a-3674-4835-846d-b2cb44b40442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>...</th>\n",
       "      <th>No_to_Grade_8</th>\n",
       "      <th>Grade_9_to_12</th>\n",
       "      <th>One_to_Two_College</th>\n",
       "      <th>Three_to_Four_College</th>\n",
       "      <th>Five_or_More_Years_College</th>\n",
       "      <th>General_and_Undefined</th>\n",
       "      <th>STEM</th>\n",
       "      <th>Humanities_Arts_and_Social_Sciences</th>\n",
       "      <th>Business_Law_and_Communication</th>\n",
       "      <th>Vocational_Health_and_Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373372</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373373</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373374</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373376</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>162000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373377</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2809390 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGION  SEX  AGE  MARST  RACE  HCOVANY  EMPSTAT  INCWAGE  INCWELFR  \\\n",
       "0            32    2   85      5     8        2        3        0         0   \n",
       "1            32    1   51      5     1        2        3    12500         0   \n",
       "2            32    2   36      6     2        2        3    16400         0   \n",
       "3            32    1   74      6     2        2        3        0         0   \n",
       "4            32    1   49      4     1        1        3        0         0   \n",
       "...         ...  ...  ...    ...   ...      ...      ...      ...       ...   \n",
       "3373372      41    1   55      6     1        2        1    21800         0   \n",
       "3373373      41    1   33      6     1        2        1    52000         0   \n",
       "3373374      41    2   27      6     1        2        1    43000         0   \n",
       "3373376      41    1   66      1     1        2        1   162000         0   \n",
       "3373377      41    2   58      1     1        2        1    25000         0   \n",
       "\n",
       "         INCINVST  ...  No_to_Grade_8  Grade_9_to_12  One_to_Two_College  \\\n",
       "0               0  ...              0              0                   1   \n",
       "1               0  ...              0              1                   0   \n",
       "2               0  ...              1              0                   0   \n",
       "3               0  ...              1              0                   0   \n",
       "4               0  ...              0              0                   1   \n",
       "...           ...  ...            ...            ...                 ...   \n",
       "3373372         0  ...              0              1                   0   \n",
       "3373373         0  ...              0              0                   0   \n",
       "3373374         0  ...              0              0                   0   \n",
       "3373376         0  ...              0              1                   0   \n",
       "3373377         0  ...              0              1                   0   \n",
       "\n",
       "         Three_to_Four_College  Five_or_More_Years_College  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "...                        ...                         ...   \n",
       "3373372                      0                           0   \n",
       "3373373                      1                           0   \n",
       "3373374                      1                           0   \n",
       "3373376                      0                           0   \n",
       "3373377                      0                           0   \n",
       "\n",
       "         General_and_Undefined  STEM  Humanities_Arts_and_Social_Sciences  \\\n",
       "0                            1     0                                    0   \n",
       "1                            1     0                                    0   \n",
       "2                            1     0                                    0   \n",
       "3                            1     0                                    0   \n",
       "4                            1     0                                    0   \n",
       "...                        ...   ...                                  ...   \n",
       "3373372                      1     0                                    0   \n",
       "3373373                      0     1                                    0   \n",
       "3373374                      0     0                                    0   \n",
       "3373376                      1     0                                    0   \n",
       "3373377                      1     0                                    0   \n",
       "\n",
       "         Business_Law_and_Communication  Vocational_Health_and_Education  \n",
       "0                                     0                                0  \n",
       "1                                     0                                0  \n",
       "2                                     0                                0  \n",
       "3                                     0                                0  \n",
       "4                                     0                                0  \n",
       "...                                 ...                              ...  \n",
       "3373372                               0                                0  \n",
       "3373373                               0                                0  \n",
       "3373374                               0                                1  \n",
       "3373376                               0                                0  \n",
       "3373377                               0                                0  \n",
       "\n",
       "[2809390 rows x 21 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586a34e",
   "metadata": {},
   "source": [
    "### Race Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ace666ac-77c9-4227-8e99-ad382a2392ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>TRANTIME</th>\n",
       "      <th>...</th>\n",
       "      <th>Vocational_Health_and_Education</th>\n",
       "      <th>White</th>\n",
       "      <th>Black_African_American</th>\n",
       "      <th>American_Indian_Alaska_Native</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Other_Asian_Pacific_Islander</th>\n",
       "      <th>Other_Race_nec</th>\n",
       "      <th>Two_Major_Races</th>\n",
       "      <th>Three_or_More_Major_Races</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373372</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373373</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373374</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373376</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>162000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373377</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2809390 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGION  SEX  AGE  MARST  HCOVANY  EMPSTAT  INCWAGE  INCWELFR  \\\n",
       "0            32    2   85      5        2        3        0         0   \n",
       "1            32    1   51      5        2        3    12500         0   \n",
       "2            32    2   36      6        2        3    16400         0   \n",
       "3            32    1   74      6        2        3        0         0   \n",
       "4            32    1   49      4        1        3        0         0   \n",
       "...         ...  ...  ...    ...      ...      ...      ...       ...   \n",
       "3373372      41    1   55      6        2        1    21800         0   \n",
       "3373373      41    1   33      6        2        1    52000         0   \n",
       "3373374      41    2   27      6        2        1    43000         0   \n",
       "3373376      41    1   66      1        2        1   162000         0   \n",
       "3373377      41    2   58      1        2        1    25000         0   \n",
       "\n",
       "         INCINVST  TRANTIME  ...  Vocational_Health_and_Education  White  \\\n",
       "0               0         0  ...                                0      0   \n",
       "1               0         0  ...                                0      1   \n",
       "2               0         0  ...                                0      0   \n",
       "3               0         0  ...                                0      0   \n",
       "4               0         0  ...                                0      1   \n",
       "...           ...       ...  ...                              ...    ...   \n",
       "3373372         0        13  ...                                0      1   \n",
       "3373373         0        10  ...                                0      1   \n",
       "3373374         0        45  ...                                1      1   \n",
       "3373376         0        10  ...                                0      1   \n",
       "3373377         0         3  ...                                0      1   \n",
       "\n",
       "         Black_African_American  American_Indian_Alaska_Native  Chinese  \\\n",
       "0                             0                              0        0   \n",
       "1                             0                              0        0   \n",
       "2                             1                              0        0   \n",
       "3                             1                              0        0   \n",
       "4                             0                              0        0   \n",
       "...                         ...                            ...      ...   \n",
       "3373372                       0                              0        0   \n",
       "3373373                       0                              0        0   \n",
       "3373374                       0                              0        0   \n",
       "3373376                       0                              0        0   \n",
       "3373377                       0                              0        0   \n",
       "\n",
       "         Japanese  Other_Asian_Pacific_Islander  Other_Race_nec  \\\n",
       "0               0                             0               0   \n",
       "1               0                             0               0   \n",
       "2               0                             0               0   \n",
       "3               0                             0               0   \n",
       "4               0                             0               0   \n",
       "...           ...                           ...             ...   \n",
       "3373372         0                             0               0   \n",
       "3373373         0                             0               0   \n",
       "3373374         0                             0               0   \n",
       "3373376         0                             0               0   \n",
       "3373377         0                             0               0   \n",
       "\n",
       "         Two_Major_Races  Three_or_More_Major_Races  \n",
       "0                      1                          0  \n",
       "1                      0                          0  \n",
       "2                      0                          0  \n",
       "3                      0                          0  \n",
       "4                      0                          0  \n",
       "...                  ...                        ...  \n",
       "3373372                0                          0  \n",
       "3373373                0                          0  \n",
       "3373374                0                          0  \n",
       "3373376                0                          0  \n",
       "3373377                0                          0  \n",
       "\n",
       "[2809390 rows x 29 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_mapping = {\n",
    "    1: 'White',\n",
    "    2: 'Black_African_American',\n",
    "    3: 'American_Indian_Alaska_Native',\n",
    "    4: 'Chinese',\n",
    "    5: 'Japanese',\n",
    "    6: 'Other_Asian_Pacific_Islander',\n",
    "    7: 'Other_Race_nec',\n",
    "    8: 'Two_Major_Races',\n",
    "    9: 'Three_or_More_Major_Races'\n",
    "}\n",
    "\n",
    "for code, category in race_mapping.items():\n",
    "    wage_data[category] = (wage_data['RACE'] == code).astype(int)\n",
    "\n",
    "wage_data = wage_data.drop(columns=['RACE'])\n",
    "wage_data\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82fb1c9b-ea6b-4543-8327-9faa41aa8606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "empstat_mapping = {\n",
    "    0: 'No Employment Data',  # Not Applicable\n",
    "    1: 'Employed',\n",
    "    2: 'Unemployed',\n",
    "    3: 'Not_in_Labor_Force'\n",
    "}\n",
    "\n",
    "for code, category in empstat_mapping.items():\n",
    "    wage_data[category] = (wage_data['EMPSTAT'] == code).astype(int)\n",
    "'''\n",
    "wage_data['Employed'] = (wage_data['EMPSTAT'] == 1).astype(int)\n",
    "wage_data = wage_data.drop(columns=['EMPSTAT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9f98c",
   "metadata": {},
   "source": [
    "### Sex mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cbd40b4-7502-49c3-aa58-0374ae5bdc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map SEX values to binary: 1 for Male, 0 for Female\n",
    "wage_data['SEX'] = wage_data['SEX'].map({1: 1, 2: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f28dd",
   "metadata": {},
   "source": [
    "### Health insurance mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b679cc2a-6e27-4dce-9274-0d22f37bc355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map HCOVANY values to binary: 1 for 'With health insurance coverage', 0 for 'No health insurance coverage'\n",
    "wage_data['HCOVANY'] = wage_data['HCOVANY'].map({1: 0, 2: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d80392",
   "metadata": {},
   "source": [
    "### Marriage Data mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35d78526-acbf-4c04-8d62-e2b78d04ba74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the mapping for MARST categories\n",
    "marst_mapping = {\n",
    "    1: 'Married_Spouse_Present',\n",
    "    2: 'Married_Spouse_Absent',\n",
    "    3: 'Separated',\n",
    "    4: 'Divorced',\n",
    "    5: 'Widowed',\n",
    "    6: 'Never_Married_Single'\n",
    "}\n",
    "\n",
    "for code, status in marst_mapping.items():\n",
    "    wage_data[status] = (wage_data['MARST'] == code).astype(int)\n",
    "\n",
    "wage_data = wage_data.drop(columns=['MARST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a4d5bf9-a2b3-47d7-842a-70fee75f9b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the mapping for REGION categories\n",
    "region_mapping = {\n",
    "    11: 'New_England_Division',\n",
    "    12: 'Middle_Atlantic_Division',\n",
    "    21: 'East_North_Central_Division',\n",
    "    22: 'West_North_Central_Division',\n",
    "    31: 'South_Atlantic_Division',\n",
    "    32: 'East_South_Central_Division',\n",
    "    33: 'West_South_Central_Division',\n",
    "    41: 'Mountain_Division',\n",
    "    42: 'Pacific_Division',\n",
    "}\n",
    "\n",
    "for code, division in region_mapping.items():\n",
    "    wage_data[division] = (wage_data['REGION'] == code).astype(int)\n",
    "\n",
    "wage_data = wage_data.drop(columns=['REGION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ef81bd3-ada4-445f-99c6-9ab5d6e7d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "int64_columns = wage_data.select_dtypes(include=['int64']).columns\n",
    "wage_data[int64_columns] = wage_data[int64_columns].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ec3df12-22a6-4b8c-b3e6-b90ec505c107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2809390 entries, 0 to 3373377\n",
      "Data columns (total 42 columns):\n",
      " #   Column                               Dtype\n",
      "---  ------                               -----\n",
      " 0   SEX                                  int32\n",
      " 1   AGE                                  int32\n",
      " 2   HCOVANY                              int32\n",
      " 3   INCWAGE                              int32\n",
      " 4   INCWELFR                             int32\n",
      " 5   INCINVST                             int32\n",
      " 6   TRANTIME                             int32\n",
      " 7   No_to_Grade_8                        int32\n",
      " 8   Grade_9_to_12                        int32\n",
      " 9   One_to_Two_College                   int32\n",
      " 10  Three_to_Four_College                int32\n",
      " 11  Five_or_More_Years_College           int32\n",
      " 12  General_and_Undefined                int32\n",
      " 13  STEM                                 int32\n",
      " 14  Humanities_Arts_and_Social_Sciences  int32\n",
      " 15  Business_Law_and_Communication       int32\n",
      " 16  Vocational_Health_and_Education      int32\n",
      " 17  White                                int32\n",
      " 18  Black_African_American               int32\n",
      " 19  American_Indian_Alaska_Native        int32\n",
      " 20  Chinese                              int32\n",
      " 21  Japanese                             int32\n",
      " 22  Other_Asian_Pacific_Islander         int32\n",
      " 23  Other_Race_nec                       int32\n",
      " 24  Two_Major_Races                      int32\n",
      " 25  Three_or_More_Major_Races            int32\n",
      " 26  Employed                             int32\n",
      " 27  Married_Spouse_Present               int32\n",
      " 28  Married_Spouse_Absent                int32\n",
      " 29  Separated                            int32\n",
      " 30  Divorced                             int32\n",
      " 31  Widowed                              int32\n",
      " 32  Never_Married_Single                 int32\n",
      " 33  New_England_Division                 int32\n",
      " 34  Middle_Atlantic_Division             int32\n",
      " 35  East_North_Central_Division          int32\n",
      " 36  West_North_Central_Division          int32\n",
      " 37  South_Atlantic_Division              int32\n",
      " 38  East_South_Central_Division          int32\n",
      " 39  West_South_Central_Division          int32\n",
      " 40  Mountain_Division                    int32\n",
      " 41  Pacific_Division                     int32\n",
      "dtypes: int32(42)\n",
      "memory usage: 471.5 MB\n"
     ]
    }
   ],
   "source": [
    "wage_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81da0c",
   "metadata": {},
   "source": [
    "## Run Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "533e9d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            LOG_INCWAGE   R-squared:                       0.740\n",
      "Model:                            OLS   Adj. R-squared:                  0.740\n",
      "Method:                 Least Squares   F-statistic:                 2.217e+05\n",
      "Date:                Tue, 19 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        20:26:44   Log-Likelihood:            -6.7413e+06\n",
      "No. Observations:             2809390   AIC:                         1.348e+07\n",
      "Df Residuals:                 2809353   BIC:                         1.348e+07\n",
      "Df Model:                          36                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================================\n",
      "                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "SEX                                     0.2563      0.003     78.074      0.000       0.250       0.263\n",
      "AGE                                    -0.0298      0.000   -262.475      0.000      -0.030      -0.030\n",
      "HCOVANY                                 0.2765      0.006     44.740      0.000       0.264       0.289\n",
      "INCWELFR                            -4.181e-05    2.3e-06    -18.200      0.000   -4.63e-05   -3.73e-05\n",
      "INCINVST                            -1.398e-06   6.45e-08    -21.682      0.000   -1.52e-06   -1.27e-06\n",
      "TRANTIME                                0.0066   9.32e-05     71.089      0.000       0.006       0.007\n",
      "No_to_Grade_8                           0.0678      0.017      3.925      0.000       0.034       0.102\n",
      "Grade_9_to_12                           0.2897      0.016     18.130      0.000       0.258       0.321\n",
      "One_to_Two_College                      0.5919      0.016     36.691      0.000       0.560       0.623\n",
      "Three_to_Four_College                   0.9582      0.016     59.960      0.000       0.927       0.989\n",
      "Five_or_More_Years_College              1.2268      0.016     75.911      0.000       1.195       1.258\n",
      "General_and_Undefined                   0.6260      0.022     28.608      0.000       0.583       0.669\n",
      "STEM                                    0.7451      0.011     68.950      0.000       0.724       0.766\n",
      "Humanities_Arts_and_Social_Sciences     0.4733      0.011     42.943      0.000       0.452       0.495\n",
      "Business_Law_and_Communication          0.7401      0.011     67.064      0.000       0.718       0.762\n",
      "Vocational_Health_and_Education         0.5497      0.011     50.030      0.000       0.528       0.571\n",
      "White                                   0.3918      0.005     75.476      0.000       0.382       0.402\n",
      "Black_African_American                  0.4749      0.007     68.838      0.000       0.461       0.488\n",
      "American_Indian_Alaska_Native           0.3901      0.014     28.162      0.000       0.363       0.417\n",
      "Chinese                                 0.3269      0.012     26.419      0.000       0.303       0.351\n",
      "Japanese                                0.3223      0.028     11.641      0.000       0.268       0.377\n",
      "Other_Asian_Pacific_Islander            0.3337      0.008     40.358      0.000       0.317       0.350\n",
      "Other_Race_nec                          0.2528      0.008     32.618      0.000       0.238       0.268\n",
      "Two_Major_Races                         0.3167      0.007     47.736      0.000       0.304       0.330\n",
      "Three_or_More_Major_Races               0.3251      0.019     17.231      0.000       0.288       0.362\n",
      "Employed                                8.2331      0.004   1978.707      0.000       8.225       8.241\n",
      "Married_Spouse_Present                  0.5993      0.005    124.056      0.000       0.590       0.609\n",
      "Married_Spouse_Absent                   0.5213      0.010     52.326      0.000       0.502       0.541\n",
      "Separated                               0.6385      0.012     53.241      0.000       0.615       0.662\n",
      "Divorced                                0.6666      0.006    109.252      0.000       0.655       0.679\n",
      "Widowed                                 0.4628      0.008     61.440      0.000       0.448       0.478\n",
      "Never_Married_Single                    0.2457      0.005     50.598      0.000       0.236       0.255\n",
      "New_England_Division                    0.4642      0.007     64.645      0.000       0.450       0.478\n",
      "Middle_Atlantic_Division                0.4032      0.005     82.457      0.000       0.394       0.413\n",
      "East_North_Central_Division             0.4103      0.005     86.406      0.000       0.401       0.420\n",
      "West_North_Central_Division             0.3522      0.006     55.934      0.000       0.340       0.365\n",
      "South_Atlantic_Division                 0.3250      0.004     77.092      0.000       0.317       0.333\n",
      "East_South_Central_Division             0.2570      0.007     39.456      0.000       0.244       0.270\n",
      "West_South_Central_Division             0.2484      0.005     50.288      0.000       0.239       0.258\n",
      "Mountain_Division                       0.3398      0.006     57.580      0.000       0.328       0.351\n",
      "Pacific_Division                        0.3341      0.005     72.545      0.000       0.325       0.343\n",
      "==============================================================================\n",
      "Omnibus:                   419063.887   Durbin-Watson:                   1.921\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4844019.043\n",
      "Skew:                          -0.339   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.397   Cond. No.                     1.01e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.75e-17. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Defining x and y variables\n",
    "\n",
    "wage_data['LOG_INCWAGE'] = np.log(wage_data['INCWAGE'] + 1) # +1 to avoid log(0)\n",
    "y = wage_data['LOG_INCWAGE']\n",
    "x = wage_data.drop(['INCWAGE','LOG_INCWAGE'],axis=1)\n",
    "\n",
    "# Run a simple linear model \n",
    "\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# Output the summary of the regression model\n",
    "model_summary = model.summary()\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcde1683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>TRANTIME</th>\n",
       "      <th>No_to_Grade_8</th>\n",
       "      <th>Grade_9_to_12</th>\n",
       "      <th>One_to_Two_College</th>\n",
       "      <th>...</th>\n",
       "      <th>New_England_Division</th>\n",
       "      <th>Middle_Atlantic_Division</th>\n",
       "      <th>East_North_Central_Division</th>\n",
       "      <th>West_North_Central_Division</th>\n",
       "      <th>South_Atlantic_Division</th>\n",
       "      <th>East_South_Central_Division</th>\n",
       "      <th>West_South_Central_Division</th>\n",
       "      <th>Mountain_Division</th>\n",
       "      <th>Pacific_Division</th>\n",
       "      <th>LOG_INCWAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>12500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.433564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>16400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.705098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373372</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.989711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373373</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.859018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373374</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.668979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373376</th>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>162000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.995358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373377</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.126671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2809390 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEX  AGE  HCOVANY  INCWAGE  INCWELFR  INCINVST  TRANTIME  \\\n",
       "0          0   85        1        0         0         0         0   \n",
       "1          1   51        1    12500         0         0         0   \n",
       "2          0   36        1    16400         0         0         0   \n",
       "3          1   74        1        0         0         0         0   \n",
       "4          1   49        0        0         0         0         0   \n",
       "...      ...  ...      ...      ...       ...       ...       ...   \n",
       "3373372    1   55        1    21800         0         0        13   \n",
       "3373373    1   33        1    52000         0         0        10   \n",
       "3373374    0   27        1    43000         0         0        45   \n",
       "3373376    1   66        1   162000         0         0        10   \n",
       "3373377    0   58        1    25000         0         0         3   \n",
       "\n",
       "         No_to_Grade_8  Grade_9_to_12  One_to_Two_College  ...  \\\n",
       "0                    0              0                   1  ...   \n",
       "1                    0              1                   0  ...   \n",
       "2                    1              0                   0  ...   \n",
       "3                    1              0                   0  ...   \n",
       "4                    0              0                   1  ...   \n",
       "...                ...            ...                 ...  ...   \n",
       "3373372              0              1                   0  ...   \n",
       "3373373              0              0                   0  ...   \n",
       "3373374              0              0                   0  ...   \n",
       "3373376              0              1                   0  ...   \n",
       "3373377              0              1                   0  ...   \n",
       "\n",
       "         New_England_Division  Middle_Atlantic_Division  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "...                       ...                       ...   \n",
       "3373372                     0                         0   \n",
       "3373373                     0                         0   \n",
       "3373374                     0                         0   \n",
       "3373376                     0                         0   \n",
       "3373377                     0                         0   \n",
       "\n",
       "         East_North_Central_Division  West_North_Central_Division  \\\n",
       "0                                  0                            0   \n",
       "1                                  0                            0   \n",
       "2                                  0                            0   \n",
       "3                                  0                            0   \n",
       "4                                  0                            0   \n",
       "...                              ...                          ...   \n",
       "3373372                            0                            0   \n",
       "3373373                            0                            0   \n",
       "3373374                            0                            0   \n",
       "3373376                            0                            0   \n",
       "3373377                            0                            0   \n",
       "\n",
       "         South_Atlantic_Division  East_South_Central_Division  \\\n",
       "0                              0                            1   \n",
       "1                              0                            1   \n",
       "2                              0                            1   \n",
       "3                              0                            1   \n",
       "4                              0                            1   \n",
       "...                          ...                          ...   \n",
       "3373372                        0                            0   \n",
       "3373373                        0                            0   \n",
       "3373374                        0                            0   \n",
       "3373376                        0                            0   \n",
       "3373377                        0                            0   \n",
       "\n",
       "         West_South_Central_Division  Mountain_Division  Pacific_Division  \\\n",
       "0                                  0                  0                 0   \n",
       "1                                  0                  0                 0   \n",
       "2                                  0                  0                 0   \n",
       "3                                  0                  0                 0   \n",
       "4                                  0                  0                 0   \n",
       "...                              ...                ...               ...   \n",
       "3373372                            0                  1                 0   \n",
       "3373373                            0                  1                 0   \n",
       "3373374                            0                  1                 0   \n",
       "3373376                            0                  1                 0   \n",
       "3373377                            0                  1                 0   \n",
       "\n",
       "         LOG_INCWAGE  \n",
       "0           0.000000  \n",
       "1           9.433564  \n",
       "2           9.705098  \n",
       "3           0.000000  \n",
       "4           0.000000  \n",
       "...              ...  \n",
       "3373372     9.989711  \n",
       "3373373    10.859018  \n",
       "3373374    10.668979  \n",
       "3373376    11.995358  \n",
       "3373377    10.126671  \n",
       "\n",
       "[2809390 rows x 43 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10392133-add6-4e9a-838f-2a179938f9d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['No Employment Data'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# define predictor and response variables\u001b[39;00m\n\u001b[1;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m wage_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOG_INCWAGE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mwage_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLOG_INCWAGE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINCWAGE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo Employment Data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(x,y,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m92\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MSQF/Machine Learning/compustats_proj/machinelearning/.venv/lib/python3.9/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MSQF/Machine Learning/compustats_proj/machinelearning/.venv/lib/python3.9/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Documents/MSQF/Machine Learning/compustats_proj/machinelearning/.venv/lib/python3.9/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/MSQF/Machine Learning/compustats_proj/machinelearning/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['No Employment Data'] not found in axis\""
     ]
    }
   ],
   "source": [
    "'''\n",
    "Splitting the training set and test set, randomly create 92 splits, test on 20% of the data.\n",
    "'''\n",
    "# define predictor and response variables\n",
    "\n",
    "y = wage_data['LOG_INCWAGE']\n",
    "x = wage_data.drop(['LOG_INCWAGE', 'INCWAGE', 'No Employment Data'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53d93fb5-1ea8-4872-9841-639f5de2d082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            LOG_INCWAGE   R-squared:                       0.747\n",
      "Model:                            OLS   Adj. R-squared:                  0.747\n",
      "Method:                 Least Squares   F-statistic:                 2.764e+05\n",
      "Date:                Tue, 19 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        20:11:27   Log-Likelihood:            -5.3610e+06\n",
      "No. Observations:             2247512   AIC:                         1.072e+07\n",
      "Df Residuals:                 2247487   BIC:                         1.072e+07\n",
      "Df Model:                          24                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================================\n",
      "                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "const                                   3.0422      0.009    328.725      0.000       3.024       3.060\n",
      "SEX                                     0.2246      0.004     62.754      0.000       0.218       0.232\n",
      "AGE                                    -0.0209   9.99e-05   -209.505      0.000      -0.021      -0.021\n",
      "HCOVANY                                 0.3738      0.007     55.242      0.000       0.361       0.387\n",
      "INCWELFR                            -5.919e-05   2.53e-06    -23.368      0.000   -6.42e-05   -5.42e-05\n",
      "INCINVST                            -1.229e-06    7.1e-08    -17.311      0.000   -1.37e-06   -1.09e-06\n",
      "TRANTIME                                0.0068      0.000     66.582      0.000       0.007       0.007\n",
      "No_to_Grade_8                           0.0732      0.017      4.302      0.000       0.040       0.107\n",
      "Grade_9_to_12                           0.2748      0.016     17.689      0.000       0.244       0.305\n",
      "One_to_Two_College                      0.5734      0.016     36.557      0.000       0.543       0.604\n",
      "Three_to_Four_College                   0.9201      0.019     47.313      0.000       0.882       0.958\n",
      "Five_or_More_Years_College              1.2007      0.020     61.274      0.000       1.162       1.239\n",
      "General_and_Undefined                   0.5972      0.026     22.888      0.000       0.546       0.648\n",
      "STEM                                    0.7272      0.010     73.629      0.000       0.708       0.747\n",
      "Humanities_Arts_and_Social_Sciences     0.4433      0.010     43.786      0.000       0.423       0.463\n",
      "Business_Law_and_Communication          0.7160      0.010     70.580      0.000       0.696       0.736\n",
      "Vocational_Health_and_Education         0.5585      0.010     55.226      0.000       0.539       0.578\n",
      "White                                   0.4214      0.005     76.724      0.000       0.411       0.432\n",
      "Black_African_American                  0.4026      0.007     55.186      0.000       0.388       0.417\n",
      "American_Indian_Alaska_Native           0.3518      0.015     23.337      0.000       0.322       0.381\n",
      "Chinese                                 0.3637      0.013     27.078      0.000       0.337       0.390\n",
      "Japanese                                0.3322      0.030     11.023      0.000       0.273       0.391\n",
      "Other_Asian_Pacific_Islander            0.3500      0.009     38.975      0.000       0.332       0.368\n",
      "Other_Race_nec                          0.2429      0.008     28.691      0.000       0.226       0.259\n",
      "Two_Major_Races                         0.3004      0.007     41.666      0.000       0.286       0.314\n",
      "Three_or_More_Major_Races               0.2773      0.020     13.527      0.000       0.237       0.317\n",
      "Employed                                5.5972      0.005   1109.823      0.000       5.587       5.607\n",
      "Unemployed                              0.3795      0.009     42.606      0.000       0.362       0.397\n",
      "Not_in_Labor_Force                     -2.9345      0.005   -561.621      0.000      -2.945      -2.924\n",
      "==============================================================================\n",
      "Omnibus:                   398024.265   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4204095.283\n",
      "Skew:                          -0.542   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.612   Cond. No.                     1.17e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.03e-17. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "## Linear regression \n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# run linear regression\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# view model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6de4e33-71ec-445a-bac6-0c3fc882eda4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.5441509764332477)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction \n",
    "\n",
    "y_pred = model.predict(sm.add_constant(X_test))\n",
    "\n",
    "np.mean(np.absolute(y_pred - y_test))\n",
    "\n",
    "# Mean of absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca786243-0e14-42cd-ac56-d57486449fcd",
   "metadata": {},
   "source": [
    "## Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2210c33f-9ecf-41f2-969f-aa4e1d7ed7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2247512, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'n_features_to_select': “auto”, int or float, default=’auto’\n",
    "# If \"auto\", the behaviour depends on the 'tol' parameter:\n",
    "# if tol is not None, then features are selected until the score improvement does not exceed 'tol'.\n",
    "# otherwise, half of the features are selected.\n",
    "\n",
    "# If the score is not incremented by at least 'tol' between two consecutive feature additions or removals, \n",
    "# stop adding or removing. 'tol' is enabled only when 'n_features_to_select' is \"auto\".\n",
    "\n",
    "sfs = SequentialFeatureSelector(LinearRegression(),\n",
    "                                 direction='forward',\n",
    "                                 cv=None,\n",
    "                                 n_features_to_select=10)  # Limit to top 10 features\n",
    "\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# shape is from numpy and returns the shape of the array \n",
    "\n",
    "sfs.transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75639139-af34-4b06-95cc-af2ad7776c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(cv=None, estimator=LinearRegression(),\n",
       "                          n_features_to_select=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SequentialFeatureSelector<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html\">?<span>Documentation for SequentialFeatureSelector</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SequentialFeatureSelector(cv=None, estimator=LinearRegression(),\n",
       "                          n_features_to_select=10)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LinearRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(cv=None, estimator=LinearRegression(),\n",
       "                          n_features_to_select=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a67749a-fd8b-4489-8f6c-3cdee4e7b8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>TRANTIME</th>\n",
       "      <th>One_to_Two_College</th>\n",
       "      <th>Five_or_More_Years_College</th>\n",
       "      <th>General_and_Undefined</th>\n",
       "      <th>Humanities_Arts_and_Social_Sciences</th>\n",
       "      <th>Employed</th>\n",
       "      <th>Not_in_Labor_Force</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3276207</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218525</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40906</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194288</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381987</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916693</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822082</th>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283362</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547387</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708540</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2247512 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEX  AGE  HCOVANY  TRANTIME  One_to_Two_College  \\\n",
       "3276207    0   29        1         8                   1   \n",
       "2218525    1   62        1         0                   0   \n",
       "40906      0   58        1         0                   1   \n",
       "2194288    1   83        1         0                   1   \n",
       "2381987    0   39        1        25                   1   \n",
       "...      ...  ...      ...       ...                 ...   \n",
       "916693     1   24        1         3                   0   \n",
       "1822082    0   74        1         0                   0   \n",
       "283362     0   28        1        45                   1   \n",
       "2547387    1   60        1        50                   0   \n",
       "708540     1   52        1        60                   0   \n",
       "\n",
       "         Five_or_More_Years_College  General_and_Undefined  \\\n",
       "3276207                           0                      1   \n",
       "2218525                           0                      1   \n",
       "40906                             0                      1   \n",
       "2194288                           0                      1   \n",
       "2381987                           0                      1   \n",
       "...                             ...                    ...   \n",
       "916693                            0                      1   \n",
       "1822082                           1                      0   \n",
       "283362                            0                      1   \n",
       "2547387                           0                      0   \n",
       "708540                            0                      0   \n",
       "\n",
       "         Humanities_Arts_and_Social_Sciences  Employed  Not_in_Labor_Force  \n",
       "3276207                                    0         1                   0  \n",
       "2218525                                    0         0                   1  \n",
       "40906                                      0         0                   1  \n",
       "2194288                                    0         0                   1  \n",
       "2381987                                    0         1                   0  \n",
       "...                                      ...       ...                 ...  \n",
       "916693                                     0         1                   0  \n",
       "1822082                                    0         0                   1  \n",
       "283362                                     0         1                   0  \n",
       "2547387                                    0         1                   0  \n",
       "708540                                     1         1                   0  \n",
       "\n",
       "[2247512 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features selected from Forward Stepwise Selection Model\n",
    "\n",
    "X_train.loc[:,sfs.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18d34ff8-5727-4ce9-b5aa-bea41ee22b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:            LOG_INCWAGE   R-squared (uncentered):                   0.889\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.889\n",
      "Method:                 Least Squares   F-statistic:                          1.799e+06\n",
      "Date:                Tue, 19 Nov 2024   Prob (F-statistic):                        0.00\n",
      "Time:                        17:51:38   Log-Likelihood:                     -5.3874e+06\n",
      "No. Observations:             2247512   AIC:                                  1.077e+07\n",
      "Df Residuals:                 2247502   BIC:                                  1.077e+07\n",
      "Df Model:                          10                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.3643      0.004    103.741      0.000       0.357       0.371\n",
      "x2            -0.0102   8.59e-05   -118.603      0.000      -0.010      -0.010\n",
      "x3             1.2527      0.006    226.798      0.000       1.242       1.264\n",
      "x4         -5.262e-05   2.56e-06    -20.536      0.000   -5.76e-05   -4.76e-05\n",
      "x5             0.0063      0.000     60.423      0.000       0.006       0.006\n",
      "x6            -0.3080      0.004    -81.800      0.000      -0.315      -0.301\n",
      "x7             0.0579      0.007      7.941      0.000       0.044       0.072\n",
      "x8             0.2265      0.004     58.848      0.000       0.219       0.234\n",
      "x9             8.9637      0.004   2116.931      0.000       8.955       8.972\n",
      "x10            3.8294      0.012    320.823      0.000       3.806       3.853\n",
      "==============================================================================\n",
      "Omnibus:                   384850.535   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4730443.726\n",
      "Skew:                          -0.454   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.049   Cond. No.                     4.69e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 4.69e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Adding a constant to the predictor values\n",
    "\n",
    "forward_x = sfs.transform(X_train)\n",
    "\n",
    "# Run a linear regression model\n",
    "\n",
    "model = sm.OLS(y_train, forward_x).fit()\n",
    "\n",
    "# view model summary\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46414868-f462-4361-ba48-31b69797518d",
   "metadata": {},
   "source": [
    "## Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "899870c1-8568-475f-bd55-d58538eb8bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2247512, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbs = SequentialFeatureSelector(LinearRegression(),\n",
    "                                direction='backward',\n",
    "                                cv=None, n_features_to_select=10)\n",
    "sbs.fit(X_train, y_train)\n",
    "\n",
    "sbs.transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "83270f95-d989-4ff5-b35f-0f3798755301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HCOVANY</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>TRANTIME</th>\n",
       "      <th>General_and_Undefined</th>\n",
       "      <th>Humanities_Arts_and_Social_Sciences</th>\n",
       "      <th>Other_Race_nec</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Not_in_Labor_Force</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3276207</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218525</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40906</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194288</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381987</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916693</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822082</th>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283362</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547387</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708540</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2247512 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEX  AGE  HCOVANY  INCWELFR  TRANTIME  General_and_Undefined  \\\n",
       "3276207    0   29        1         0         8                      1   \n",
       "2218525    1   62        1         0         0                      1   \n",
       "40906      0   58        1         0         0                      1   \n",
       "2194288    1   83        1         0         0                      1   \n",
       "2381987    0   39        1         0        25                      1   \n",
       "...      ...  ...      ...       ...       ...                    ...   \n",
       "916693     1   24        1         0         3                      1   \n",
       "1822082    0   74        1         0         0                      0   \n",
       "283362     0   28        1         0        45                      1   \n",
       "2547387    1   60        1         0        50                      0   \n",
       "708540     1   52        1         0        60                      0   \n",
       "\n",
       "         Humanities_Arts_and_Social_Sciences  Other_Race_nec  Unemployed  \\\n",
       "3276207                                    0               0           0   \n",
       "2218525                                    0               0           0   \n",
       "40906                                      0               0           0   \n",
       "2194288                                    0               0           0   \n",
       "2381987                                    0               0           0   \n",
       "...                                      ...             ...         ...   \n",
       "916693                                     0               0           0   \n",
       "1822082                                    0               0           0   \n",
       "283362                                     0               0           0   \n",
       "2547387                                    0               0           0   \n",
       "708540                                     1               0           0   \n",
       "\n",
       "         Not_in_Labor_Force  \n",
       "3276207                   0  \n",
       "2218525                   1  \n",
       "40906                     1  \n",
       "2194288                   1  \n",
       "2381987                   0  \n",
       "...                     ...  \n",
       "916693                    0  \n",
       "1822082                   1  \n",
       "283362                    0  \n",
       "2547387                   0  \n",
       "708540                    0  \n",
       "\n",
       "[2247512 rows x 10 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[:,sbs.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2ce3e078-734d-4cc5-88d2-c6c6c2d38645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:            LOG_INCWAGE   R-squared (uncentered):                   0.820\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.820\n",
      "Method:                 Least Squares   F-statistic:                          1.022e+06\n",
      "Date:                Tue, 19 Nov 2024   Prob (F-statistic):                        0.00\n",
      "Time:                        19:00:52   Log-Likelihood:                     -5.9318e+06\n",
      "No. Observations:             2247512   AIC:                                  1.186e+07\n",
      "Df Residuals:                 2247502   BIC:                                  1.186e+07\n",
      "Df Model:                          10                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.2161      0.004    274.310      0.000       1.207       1.225\n",
      "x2             0.0290      0.000    252.498      0.000       0.029       0.029\n",
      "x3             5.9948      0.006    948.760      0.000       5.982       6.007\n",
      "x4         -5.019e-05   3.26e-06    -15.373      0.000   -5.66e-05   -4.38e-05\n",
      "x5             0.0351      0.000    273.205      0.000       0.035       0.035\n",
      "x6             1.3651      0.005    274.562      0.000       1.355       1.375\n",
      "x7             1.5392      0.009    166.422      0.000       1.521       1.557\n",
      "x8             0.9420      0.010     93.882      0.000       0.922       0.962\n",
      "x9            -3.2467      0.015   -211.601      0.000      -3.277      -3.217\n",
      "x10           -8.1675      0.006  -1389.820      0.000      -8.179      -8.156\n",
      "==============================================================================\n",
      "Omnibus:                   173164.332   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           873793.279\n",
      "Skew:                           0.191   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.031   Cond. No.                     4.74e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 4.74e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#add constant to predictor variables\n",
    "backward_x = sbs.transform(X_train)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y_train, backward_x).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb9940-8f6d-4a42-9960-8fea9e6e6842",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e145eafe-3fe5-4d42-b606-ae7d7201c74b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.31670791e+12  1.06585316e-01 -4.11791314e-01  1.12025903e-01\n",
      " -4.18961671e-02 -2.57141171e-02  1.37752359e-01 -4.17671862e+12\n",
      " -7.41613348e+11  4.95048813e+12  8.15393514e+12  2.02671227e+11\n",
      " -5.28937119e+09 -3.32264498e+09 -2.97007088e+09 -3.00773293e+09\n",
      " -3.01532564e+09  7.15170532e+11  4.38305879e+11  1.67900928e+11\n",
      "  1.91981147e+11  8.06748919e+10  3.17675890e+11  3.47972337e+11\n",
      "  4.44399550e+11  1.20297977e+11  2.08312510e+11  6.31761349e+10\n",
      "  2.06889033e+11]\n"
     ]
    }
   ],
   "source": [
    "X_train_std = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "clf = Ridge(alpha=0) ## alpha is = lambda in python(avoid confusion w lambda functions)\n",
    "\n",
    "clf.fit(X_train_std,y_train)\n",
    "\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0ae79c6e-1ef0-4a08-86fc-8c2c20b2c790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2247512.0</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2247512.0</td>\n",
       "      <td>2247512.0</td>\n",
       "      <td>2247512.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "      <td>2.247512e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.750702e-17</td>\n",
       "      <td>-1.812783e-17</td>\n",
       "      <td>-2.004368e-17</td>\n",
       "      <td>-1.028108e-17</td>\n",
       "      <td>2.078346e-17</td>\n",
       "      <td>-3.420704e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289358e-18</td>\n",
       "      <td>-3.241132e-17</td>\n",
       "      <td>1.060671e-18</td>\n",
       "      <td>-5.094541e-17</td>\n",
       "      <td>-8.221070e-17</td>\n",
       "      <td>2.259340e-17</td>\n",
       "      <td>-8.352587e-18</td>\n",
       "      <td>4.451025e-17</td>\n",
       "      <td>-7.462003e-17</td>\n",
       "      <td>-2.901591e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.737488e-01</td>\n",
       "      <td>-1.710362e+00</td>\n",
       "      <td>-3.436863e+00</td>\n",
       "      <td>-6.999127e-02</td>\n",
       "      <td>-2.407242e-01</td>\n",
       "      <td>-6.028069e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.106100e-01</td>\n",
       "      <td>-1.269589e-01</td>\n",
       "      <td>-5.265029e-02</td>\n",
       "      <td>-2.164344e-01</td>\n",
       "      <td>-2.394520e-01</td>\n",
       "      <td>-3.185774e-01</td>\n",
       "      <td>-7.877808e-02</td>\n",
       "      <td>-1.129819e+00</td>\n",
       "      <td>-1.540890e-01</td>\n",
       "      <td>-8.441341e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.737488e-01</td>\n",
       "      <td>-8.493167e-01</td>\n",
       "      <td>2.909630e-01</td>\n",
       "      <td>-6.999127e-02</td>\n",
       "      <td>-1.206598e-01</td>\n",
       "      <td>-6.028069e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.106100e-01</td>\n",
       "      <td>-1.269589e-01</td>\n",
       "      <td>-5.265029e-02</td>\n",
       "      <td>-2.164344e-01</td>\n",
       "      <td>-2.394520e-01</td>\n",
       "      <td>-3.185774e-01</td>\n",
       "      <td>-7.877808e-02</td>\n",
       "      <td>-1.129819e+00</td>\n",
       "      <td>-1.540890e-01</td>\n",
       "      <td>-8.441341e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.737488e-01</td>\n",
       "      <td>1.172822e-02</td>\n",
       "      <td>2.909630e-01</td>\n",
       "      <td>-6.999127e-02</td>\n",
       "      <td>-1.206598e-01</td>\n",
       "      <td>-6.028069e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.106100e-01</td>\n",
       "      <td>-1.269589e-01</td>\n",
       "      <td>-5.265029e-02</td>\n",
       "      <td>-2.164344e-01</td>\n",
       "      <td>-2.394520e-01</td>\n",
       "      <td>-3.185774e-01</td>\n",
       "      <td>-7.877808e-02</td>\n",
       "      <td>8.850973e-01</td>\n",
       "      <td>-1.540890e-01</td>\n",
       "      <td>-8.441341e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.026959e+00</td>\n",
       "      <td>8.221234e-01</td>\n",
       "      <td>2.909630e-01</td>\n",
       "      <td>-6.999127e-02</td>\n",
       "      <td>-1.206598e-01</td>\n",
       "      <td>3.818873e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.106100e-01</td>\n",
       "      <td>-1.269589e-01</td>\n",
       "      <td>-5.265029e-02</td>\n",
       "      <td>-2.164344e-01</td>\n",
       "      <td>-2.394520e-01</td>\n",
       "      <td>-3.185774e-01</td>\n",
       "      <td>-7.877808e-02</td>\n",
       "      <td>8.850973e-01</td>\n",
       "      <td>-1.540890e-01</td>\n",
       "      <td>1.184646e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.026959e+00</td>\n",
       "      <td>2.392264e+00</td>\n",
       "      <td>2.909630e-01</td>\n",
       "      <td>4.322503e+01</td>\n",
       "      <td>1.860940e+01</td>\n",
       "      <td>7.176277e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.040773e+00</td>\n",
       "      <td>7.876565e+00</td>\n",
       "      <td>1.899325e+01</td>\n",
       "      <td>4.620337e+00</td>\n",
       "      <td>4.176203e+00</td>\n",
       "      <td>3.138955e+00</td>\n",
       "      <td>1.269389e+01</td>\n",
       "      <td>8.850973e-01</td>\n",
       "      <td>6.489754e+00</td>\n",
       "      <td>1.184646e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4   \\\n",
       "count  2247512.0  2.247512e+06  2.247512e+06  2.247512e+06  2.247512e+06   \n",
       "mean         0.0 -5.750702e-17 -1.812783e-17 -2.004368e-17 -1.028108e-17   \n",
       "std          0.0  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min          0.0 -9.737488e-01 -1.710362e+00 -3.436863e+00 -6.999127e-02   \n",
       "25%          0.0 -9.737488e-01 -8.493167e-01  2.909630e-01 -6.999127e-02   \n",
       "50%          0.0 -9.737488e-01  1.172822e-02  2.909630e-01 -6.999127e-02   \n",
       "75%          0.0  1.026959e+00  8.221234e-01  2.909630e-01 -6.999127e-02   \n",
       "max          0.0  1.026959e+00  2.392264e+00  2.909630e-01  4.322503e+01   \n",
       "\n",
       "                 5             6          7          8          9   ...  \\\n",
       "count  2.247512e+06  2.247512e+06  2247512.0  2247512.0  2247512.0  ...   \n",
       "mean   2.078346e-17 -3.420704e-17        0.0        0.0        0.0  ...   \n",
       "std    1.000000e+00  1.000000e+00        0.0        0.0        0.0  ...   \n",
       "min   -2.407242e-01 -6.028069e-01        0.0        0.0        0.0  ...   \n",
       "25%   -1.206598e-01 -6.028069e-01        0.0        0.0        0.0  ...   \n",
       "50%   -1.206598e-01 -6.028069e-01        0.0        0.0        0.0  ...   \n",
       "75%   -1.206598e-01  3.818873e-01        0.0        0.0        0.0  ...   \n",
       "max    1.860940e+01  7.176277e+00        0.0        0.0        0.0  ...   \n",
       "\n",
       "                 19            20            21            22            23  \\\n",
       "count  2.247512e+06  2.247512e+06  2.247512e+06  2.247512e+06  2.247512e+06   \n",
       "mean   8.289358e-18 -3.241132e-17  1.060671e-18 -5.094541e-17 -8.221070e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.106100e-01 -1.269589e-01 -5.265029e-02 -2.164344e-01 -2.394520e-01   \n",
       "25%   -1.106100e-01 -1.269589e-01 -5.265029e-02 -2.164344e-01 -2.394520e-01   \n",
       "50%   -1.106100e-01 -1.269589e-01 -5.265029e-02 -2.164344e-01 -2.394520e-01   \n",
       "75%   -1.106100e-01 -1.269589e-01 -5.265029e-02 -2.164344e-01 -2.394520e-01   \n",
       "max    9.040773e+00  7.876565e+00  1.899325e+01  4.620337e+00  4.176203e+00   \n",
       "\n",
       "                 24            25            26            27            28  \n",
       "count  2.247512e+06  2.247512e+06  2.247512e+06  2.247512e+06  2.247512e+06  \n",
       "mean   2.259340e-17 -8.352587e-18  4.451025e-17 -7.462003e-17 -2.901591e-17  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -3.185774e-01 -7.877808e-02 -1.129819e+00 -1.540890e-01 -8.441341e-01  \n",
       "25%   -3.185774e-01 -7.877808e-02 -1.129819e+00 -1.540890e-01 -8.441341e-01  \n",
       "50%   -3.185774e-01 -7.877808e-02  8.850973e-01 -1.540890e-01 -8.441341e-01  \n",
       "75%   -3.185774e-01 -7.877808e-02  8.850973e-01 -1.540890e-01  1.184646e+00  \n",
       "max    3.138955e+00  1.269389e+01  8.850973e-01  6.489754e+00  1.184646e+00  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics of standardized data\n",
    "pd.DataFrame(X_train_std).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5cbe4ca8-1bff-4256-8609-27684c5dad84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.31670791e+12  1.06585316e-01 -4.11791314e-01  1.12025903e-01\n",
      " -4.18961671e-02 -2.57141171e-02  1.37752359e-01 -4.17671862e+12\n",
      " -7.41613348e+11  4.95048813e+12  8.15393514e+12  2.02671227e+11\n",
      " -5.28937119e+09 -3.32264498e+09 -2.97007088e+09 -3.00773293e+09\n",
      " -3.01532564e+09  7.15170532e+11  4.38305879e+11  1.67900928e+11\n",
      "  1.91981147e+11  8.06748919e+10  3.17675890e+11  3.47972337e+11\n",
      "  4.44399550e+11  1.20297977e+11  2.08312510e+11  6.31761349e+10\n",
      "  2.06889033e+11]\n"
     ]
    }
   ],
   "source": [
    "clf = Ridge(alpha=0)\n",
    "clf.fit(X_train_std,y_train)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a8ab988-d034-4b0c-a3a8-2ee315965a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "2 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 277, in _preprocess_data\n",
      "    y = y - y_offset\n",
      "        ~~^~~~~~~~~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (2022761,) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "3 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022760, 29) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "2 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "2 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 277, in _preprocess_data\n",
      "    y = y - y_offset\n",
      "        ~~^~~~~~~~~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (2022761,) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 277, in _preprocess_data\n",
      "    y = y - y_offset\n",
      "        ~~^~~~~~~~~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (2022761,) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022760, 29) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 277, in _preprocess_data\n",
      "    y = y - y_offset\n",
      "        ~~^~~~~~~~~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (2022761,) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 277, in _preprocess_data\n",
      "    y = y - y_offset\n",
      "        ~~^~~~~~~~~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (2022760,) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 277, in _preprocess_data\n",
      "    y = y - y_offset\n",
      "        ~~^~~~~~~~~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (2022761,) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 277, in _preprocess_data\n",
      "    y = y - y_offset\n",
      "        ~~^~~~~~~~~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (2022760,) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022760, 29) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "9 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022760, 29) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n",
      "    array = _asarray_with_order(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n",
      "    return xp.asarray(array, copy=copy)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n",
      "    return numpy.array(x, copy=True, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n                                        ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n    array = _asarray_with_order(\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n    return xp.asarray(array, copy=copy)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n    return numpy.array(x, copy=True, dtype=dtype)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022760, 29) and data type float64\n\n--------------------------------------------------------------------------------\n8 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n                                        ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n    array = _asarray_with_order(\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n    return xp.asarray(array, copy=copy)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n    return numpy.array(x, copy=True, dtype=dtype)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# This loop iterates over lambda values from 0 to 999 (1000 in total).\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# For each lambda value, it evaluates the mean absolute error (MAE) using the evaluate_lambda function and stores the result in the DataFrame lambda_score_ridge.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m---> 24\u001b[0m     lambda_score_ridge\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_lambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[1;32mIn[116], line 11\u001b[0m, in \u001b[0;36mevaluate_lambda\u001b[1;34m(X, y, lmd)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_lambda\u001b[39m(X, y, lmd):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# evaluate model - MAE\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     model \u001b[38;5;241m=\u001b[39m Ridge(alpha\u001b[38;5;241m=\u001b[39mlmd)\n\u001b[1;32m---> 11\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_absolute_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# force scores to be positive\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabsolute(scores)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n                                        ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n    array = _asarray_with_order(\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n    return xp.asarray(array, copy=copy)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n    return numpy.array(x, copy=True, dtype=dtype)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022760, 29) and data type float64\n\n--------------------------------------------------------------------------------\n8 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1134, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 866, in fit\n    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n                                        ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 230, in _preprocess_data\n    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n    array = _asarray_with_order(\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n    return xp.asarray(array, copy=copy)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michael\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n    return numpy.array(x, copy=True, dtype=dtype)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 448. MiB for an array with shape (2022761, 29) and data type float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Choose the best lambda using cross validation\n",
    "\n",
    "# We first define a function evaluate_lambda based on three arguments \n",
    "\n",
    "def evaluate_lambda(X, y, lmd):\n",
    "    # evaluate model - MAE\n",
    "    model = Ridge(alpha=lmd)\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=10)\n",
    "    # force scores to be positive\n",
    "    return np.absolute(scores)\n",
    "\n",
    "# This creates a DataFrame with two columns: 'lambda' for the lambda values and 'MAE' to store the mean absolute error.\n",
    "\n",
    "lambda_score_ridge = pd.DataFrame({'lambda':range(1000),'MAE':0}) ## MAE = mean absolute error\n",
    "\n",
    "# This loop iterates over lambda values from 0 to 999 (1000 in total).\n",
    "\n",
    "# For each lambda value, it evaluates the mean absolute error (MAE) using the evaluate_lambda function and stores the result in the DataFrame lambda_score_ridge.\n",
    "\n",
    "for i in range(1000):\n",
    "    lambda_score_ridge.loc[i,'MAE'] = evaluate_lambda(X_train_std,y_train,i).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95035968-fb9f-49c6-b383-5a6ad793c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best lambda\n",
    "\n",
    "lambda_score_ridge.loc[lambda_score_ridge.MAE.idxmin(),'lambda']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
